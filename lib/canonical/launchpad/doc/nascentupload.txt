== NascentUpload ==

Import the test keys so we have them ready for verification

  >>> from canonical.launchpad.ftests import import_public_test_keys
  >>> import_public_test_keys()

We need to be logged into the security model in order to get any further

  >>> login('foo.bar@canonical.com')

For the purpose of this test, hoary needs to be an open (development)
distroseries so that we can upload to it.

  >>> from canonical.launchpad.interfaces import IDistributionSet
  >>> ubuntu = getUtility(IDistributionSet)['ubuntu']
  >>> hoary = ubuntu['hoary']
  >>> from canonical.lp.dbschema import DistroSeriesStatus
  >>> hoary.status = DistroSeriesStatus.DEVELOPMENT

A NascentUpload is a collection of files in a directory. They
represent what may turn out to be an acceptable upload to a launchpad
managed archive.

  >>> from canonical.archiveuploader.nascentupload import NascentUpload
  >>> from canonical.archiveuploader.tests import (
  ...    datadir, getPolicy, mock_logger, mock_logger_quiet)

  >>> buildd_policy = getPolicy(
  ...     name='buildd', distro='ubuntu', distroseries='hoary', buildid=1)

  >>> sync_policy = getPolicy(
  ...     name='sync', distro='ubuntu', distroseries='hoary')

  >>> insecure_policy = getPolicy(
  ...     name='insecure', distro='ubuntu', distroseries='hoary')

  >>> anything_policy = getPolicy(
  ...     name='anything', distro='ubuntu', distroseries='hoary')

== Constructing a NascentUpload object ==

Constructing a NascentUpload instance verifies that the changes file
specified exists and tries to build a ChangesFile (see
doc/nascentuploadfile.txt) object based on that. If anything goes
wrong during this process FatalUploadError is raised:

  >>> NascentUpload(datadir("DOES-NOT-EXIST"), buildd_policy, mock_logger)
  Traceback (most recent call last):
  ...
  FatalUploadError:...

Otherwise a ChangesFile object is ready to use.

  >>> quodlibet = NascentUpload(
  ...     datadir("quodlibet_0.13.1-1_i386.changes"),
  ...     anything_policy, mock_logger_quiet)

  >>> quodlibet.changes
  <canonical.archiveuploader.changesfile.ChangesFile ...>


== NascentUpload Processing ==

Processing a NascentUpload consists of building files objects for each
specified file in the upload, executing all their specific checks and
collect all errors that may be generated. (see doc/nascentuploadfile.txt)

  >>> quodlibet.process()
  >>> for f in quodlibet.changes.files:
  ...     print f.filename, f
  quodlibet_0.13.1-1_all.deb <...DebBinaryUploadFile...>
  quodlibet-ext_0.13.1-1_i386.deb <...DebBinaryUploadFile...>

After that there are also some overall_checks which helps to
investigate if the files contained in the uploads have a sane
relationship.

Now, the upload of quodlibet was signed, and the "anything" policy
verifies the signer. When we do signature verification, we parse the
maintainer field of the changes file, and ensure that a Person record
exists for it:

  >>> quodlibet.changes.signer is not None
  True
  >>> p = quodlibet.changes.maintainer['person']
  >>> p.name, p.displayname
  (u'buildd', u'Ubuntu/i386 Build Daemon')


=== Sourceful Uploads ===

We can check if the uploads contents are 'sourceful' (contains source
files) or 'binaryful' (contain binary files):

  >>> quodlibet.sourceful
  False
  >>> quodlibet.binaryful
  True

We can distinguish between the arch-indep and arch-dep binary uploads
and therefore check if it matches what is described in the changesfiles:

  >>> quodlibet.archdep
  True
  >>> quodlibet.archindep
  True

The same happens for source uploads, where we can identify if a source
is 'native' (only a TARBALL, no diff + orig) or 'has_orig' (uses ORIG
+ DIFF source form).

  >>> ed_source_upload = NascentUpload(
  ...     datadir("ed_0.2-20_i386.changes.source-only-unsigned"),
  ...     sync_policy, mock_logger_quiet)

  >>> ed_source_upload.process()
  >>> for f in ed_source_upload.changes.files:
  ...     print f.filename, f
  ed_0.2-20.dsc <...DSCFile...>
  ed_0.2-20.diff.gz <...SourceUploadFile...>
  ed_0.2.orig.tar.gz <...SourceUploadFile...>

Since the sync_policy doesn't require the upload to be signed, we don't
try and parse the maintainer for it:

  >>> ed_source_upload.changes.signer is None
  True
  >>> print ed_source_upload.changes.maintainer
  None

ed_source upload is *sourceful*:

  >>> ed_source_upload.sourceful
  True
  >>> ed_source_upload.binaryful
  False

ed_source is uses ORIG + DIFF form:

  >>> ed_source_upload.native
  False
  >>> ed_source_upload.hasorig
  True

For *sourceful* uploads 'archdep' and 'archindep' are always False:

  >>> ed_source_upload.archdep
  False
  >>> ed_source_upload.archindep
  False


=== Binaryful Uploads ===

Let's try a simple binary upload:

  >>> ed_binary_upload = NascentUpload(
  ...     datadir("ed_0.2-20_i386.changes.binary-only-unsigned"),
  ...     buildd_policy, mock_logger_quiet)

  >>> ed_binary_upload.process()
  >>> for f in ed_binary_upload.changes.files:
  ...     print f.filename, f
  ed_0.2-20_i386.deb <...DebBinaryUploadFile...>

ed_binary is *binaryful*:

  >>> ed_binary_upload.sourceful
  False
  >>> ed_binary_upload.binaryful
  True

ed_binary contains only one 'architecture dependent binary':

  >>> ed_binary_upload.archdep
  True
  >>> ed_binary_upload.archindep
  False
  >>> ed_binary_upload.is_ppa
  False

As expected 'native' and 'hasorig' doesn't make any sense for binary
uploads, so they are alway False:

  >>> ed_binary_upload.native
  False
  >>> ed_binary_upload.hasorig
  False

Since the binary policy lets things through unsigned, we don't try and
parse the maintainer for them either:

  >>> ed_binary_upload.changes.signer is None
  True
  >>> print ed_binary_upload.changes.maintainer
  None

Other ChangesFile information are also checked across the uploads
files specified. For instance, the changesfile Architecture list line
should match the files target architectures:

XXX cprov 20070404: we need to a policy that accepts unsigned
changesfiles and binary, source and mixed uploads ...

  >>> modified_buildd_policy = getPolicy(
  ...     name='buildd', distro='ubuntu', distroseries='hoary', buildid=1)
  >>> modified_buildd_policy.can_upload_source = True
  >>> modified_buildd_policy.can_upload_mixed = True

  >>> ed_mismatched_upload = NascentUpload(
  ...     datadir("ed_0.2-20_i386.changes.mismatched-arch-unsigned"),
  ...     modified_buildd_policy, mock_logger_quiet)

  >>> ed_mismatched_upload.process()

  >>> for f in ed_mismatched_upload.changes.files:
  ...     print f.filename, f
  ed_0.2-20.dsc <...DSCFile...>
  ed_0.2-20.diff.gz <...SourceUploadFile...>
  ed_0.2-20_i386.deb <...DebBinaryUploadFile...>

  >>> [a for a in ed_mismatched_upload.changes.architectures]
  ['source', 'amd64']

Since the changesfile specify that only 'source' (pseudo-architecture
to represent source in debian format) and 'amd64' will be used and
there is a file that depends on 'i386' the upload is rejected:

  >>> print ed_mismatched_upload.rejection_message
  ed_0.2-20_i386.deb: control file lists arch as 'i386' which isn't in the changes file.


=== Mixed Uploads ===

Uploads can also contain sources and binaries together and we call it
'mixed' mode. This feature is specially useful for uploading security
fixed into ubuntu since they are assembled and built in a external
system.

XXX cprov 20070404: we need a policy that accepts mixed uploads to
RELEASE pocket ...

  >>> modified_insecure_policy = getPolicy(
  ...     name='insecure', distro='ubuntu', distroseries='hoary')
  >>> modified_insecure_policy.can_upload_binaries = True
  >>> modified_insecure_policy.can_upload_mixed = True

  >>> ed_mixed_upload = NascentUpload(
  ...     datadir("ed_0.2-20_i386.changes"),
  ...     modified_insecure_policy, mock_logger_quiet)

  >>> ed_mixed_upload.process()
  >>> ed_mixed_upload.is_rejected
  False

The NascentUpload can tell us if it is sourceful or not, (ditto binaryful)

  >>> ed_mixed_upload.sourceful
  True
  >>> ed_mixed_upload.binaryful
  True

Also provide architecture dependent status:

  >>> ed_mixed_upload.archindep
  False
  >>> ed_mixed_upload.archdep
  True

This mixed upload explores another feature in Soyuz, it does not
upload the ORIG files assuming it is already published by its
ancestries (it saves a lot of bandwidth). So, the upload is not
'native', neither 'hasorig':

  >>> ed_mixed_upload.native
  False
  >>> ed_mixed_upload.hasorig
  False

But if we check the DSC we will find the reference to the already
known ORIG file:

  >>> [f.filename for f in ed_mixed_upload.changes.dsc.files]
  ['ed_0.2.orig.tar.gz', 'ed_0.2-20.diff.gz']

  >>> success = ed_mixed_upload.do_accept()
  >>> success
  True

The notification message generated is described in more detail in
doc/nascentupload-announcements.txt.

Roll back everything related with ed_mixed_upload:

  >>> transaction.abort()


== Acceptance Work-flow ==

The NascentUpload.do_accept method is the code which effectivelly adds
information to the database. Respective PackageUploadQueue,
SourcePackageRelease, Build and BinaryPackageRelease will only exist
after calling this method.

First up, construct an upload of just the ed source...

  >>> ed_src = NascentUpload(
  ...     datadir('split-upload-test/ed_0.2-20_source.changes'),
  ...     sync_policy, mock_logger_quiet)
  >>> ed_src.process()
  >>> ed_src.is_rejected
  False
  >>> success = ed_src.do_accept()
  >>> success
  True


=== SourcePackageRelease Details ===

Retrive the just-inserted SourcePackageRelease correspondent to 'ed'

  >>> ed_spr = ed_src.queue_root.sources[0].sourcepackagerelease

Check if we have rebuid the change's author line properly (as
mentioned in bug # 30621)

  >>> print ed_spr.changelog
  ed (0.2-20) unstable; urgency=low
  ...
   -- James Troup <james@nocrew.org>  Wed,  2 Apr 2003 17:19:47 +0100

Some new fields required for NoMoreAptFtparchive implementation are
present in SourcePackageRelease. They are cached from the DSC and used
for the archive index generation:

The 'Maintainer:' identity in RFC-822 format, as it was in DSC:

  >>> ed_spr.dsc_maintainer_rfc822
  u'James Troup <james@nocrew.org>'

Version of debian policy/standards used to build this source package:

  >>> ed_spr.dsc_standards_version
  u'3.5.8.0'

Format of the included DSC (.dsc) file:

  >>> ed_spr.dsc_format
  u'1.0'

Binaries names claimed to be resulted of this source, line with names
separated by space:

  >>> ed_spr.dsc_binaries
  u'ed'

The content of 'debian/copyright' is stored as the 'copyright'
attribute of SourcePackageRelease (note that its content is filtered
with encoding.guess()).

  >>> print ed_spr.copyright
  This is Debian GNU's prepackaged version of the FSF's GNU ed
  ...
  by the Foundation.

The ed source would be in NEW, so punt it into accepted.

  >>> ed_src.queue_root.setAccepted()
  >>> from canonical.launchpad.ftests import syncUpdate
  >>> syncUpdate(ed_src.queue_root)


=== Allow uploads missing debian/copyright file ===

Some source uploads use a fancy approach to build debian/copyright
on-the-fly for each binary they generate, sometimes using templates or
another similar feature.

Soyuz is prepared to accept those uploads (and avoid extra work on
maintainer's side), however it cannot store a proper
SourcePackageRelease.copyright content. See bug #134567.

  >>> nocopyright_src = NascentUpload(
  ...     datadir('suite/nocopyright_1.0-1/nocopyright_1.0-1_source.changes'),
  ...     sync_policy, mock_logger_quiet)
  >>> nocopyright_src.process()

  >>> nocopyright_src.is_rejected
  False
  >>> success = nocopyright_src.do_accept()
  >>> success
  True

On the absence of debian/copyright a warning is issued in the upload
processing log messages, then it can be further checked in Soyuz
production mailbox.

  >>> print nocopyright_src.warning_message
  No copyright file found.

Nothing is stored in the SPR.copyright field.

  >>> nocopyright_queue = nocopyright_src.queue_root
  >>> nocopyright_spr = nocopyright_queue.sources[0].sourcepackagerelease

  >>> nocopyright_spr.copyright is None
  True

Let's reject the upload to avoid confusion during the next tests:

  >>> nocopyright_queue.setRejected()
  >>> syncUpdate(nocopyright_queue)


=== Refuse to ACCEPT duplicated sources ===

Check if we refuse duplicated uploads even before publishing (bug #31038)
The uploaded source will be considered okay, since it still passing
all the consistency checks.

However there is another candidate, submitted before and not yet
published in the archive, which provides the same source package name
and source package version for the distroseries in question.

  >>> ed_src_dup = NascentUpload(
  ...     datadir('split-upload-test/ed_0.2-20_source.changes'),
  ...     sync_policy, mock_logger_quiet)
  >>> ed_src_dup.process()
  >>> ed_src_dup.is_rejected
  False

This is a special trick to make do_accept() consider this upload OLD
(publication already present in the archive), so it will try to
automatically promote the queue entry to ACCEPTED.

  >>> for upload_file in ed_src_dup.changes.files:
  ...     upload_file.new = False

The we invoke do_accept() normally, since the upload is consistent.
but since the uniqueness check in IUpload.setAccepted() has detected
another accepted candidate that conflicts with the proposed one.
The upload will be rejected.

  >>> success = ed_src_dup.do_accept()
  ERROR: Exception while accepting:
  This sourcepackagerelease is already accepted in hoary.
  <BLANKLINE>
  Traceback...
  ...
  >>> success
  False
  >>> ed_src_dup.is_rejected
  True

  >>> print ed_src_dup.rejection_message
  This sourcepackagerelease is already accepted in hoary.

We rely on process-upload transaction rollback to not store bogus
queue entry in the database.

  >>> from canonical.lp.dbschema import PackageUploadStatus
  >>> hoary.getQueueItems(PackageUploadStatus.NEW).count()
  1


=== Building From ACCEPTED queue ===

XXX cprov 20060728: Building from ACCEPTED is special condition, not
really used in production. We should remove the support for this use
case, see further info in bug #55774.

Next we send in the binaries, since the source should be in ACCEPTED the
binary should go straight there too. Note that we are not specifying
any build, so it should be created appropriately, it is what happens
with staged security uploads:

XXX cprov 20070404: we are using a modified sync policy because we
need unsigned changes and binaries uploads (same as security, but also
accepts non-security uploads)

  >>> modified_sync_policy = getPolicy(
  ...     name='sync', distro='ubuntu', distroseries='hoary')
  >>> modified_sync_policy.can_upload_binaries = True

  >>> ed_bin = NascentUpload(
  ...      datadir('split-upload-test/ed_0.2-20_i386.changes'),
  ...      modified_sync_policy, mock_logger_quiet)

  >>> ed_bin.process()
  >>> ed_bin.is_rejected
  False

  >>> success = ed_bin.do_accept()

  >>> ed_bin.queue_root.status.name
  'NEW'

A build was created to represent the relationship between ed_src
(waiting in ACCEPTED queue) and the just uploaded ed_bin:

  >>> ed_build = ed_bin.queue_root.builds[0].build

  >>> ed_spr.id  == ed_build.sourcepackagerelease.id
  True

  >>> ed_build.title
  u'i386 build of ed 0.2-20 in ubuntu hoary RELEASE'

  >>> ed_build.buildstate.name
  'FULLYBUILT'


=== Staged Source and Binary upload with multiple binaries ===

As we could see both, sources and binaries, get into Launchpad via
nascent-upload infrastructure, i.e., both are processed as 'uploads'.

However in Launchpad the package life-cycle can be described in 10
different stages:

  1. Source upload                     DRQ->DRQS->SPR
  2  Queue review (approval/rejection) DRQ ACCEPTED or REJECTED
  3. Source queue acceptance           pending SSPPH
  4. Source publication                published SSPPH
  5. Build creation                    needsbuild Build
  6. Build dispatching                 building Build
  7. Build gathering & Binary upload   fullybuilt Build + DRQ->DRQB->BPR
  8  Queue review (approval/rejection) DRQ ACCEPTED or REJECTED
  9. Binary queue acceptance          pending SBPPH
 10. Binary publication               published SBPPH

We will try to simulate this procedure for a source upload that
produces multiple binaries using sync policy:

  >>> sync_policy = getPolicy(
  ...     name='sync', distro='ubuntu', distroseries='hoary')

Upload new source 'multibar', step 1:

  >>> multibar_src_upload = NascentUpload(
  ...     datadir('suite/multibar_1.0-1/multibar_1.0-1_source.changes'),
  ...     sync_policy, mock_logger_quiet)
  >>> multibar_src_upload.process()
  >>> success = multibar_src_upload.do_accept()
  >>> multibar_src_queue = multibar_src_upload.queue_root
  >>> multibar_src_queue.status.name
  'NEW'

  >>> multibar_src_queue.sources.count()
  1
  >>> multibar_spr = multibar_src_queue.sources[0].sourcepackagerelease
  >>> multibar_spr.title
  u'multibar - 1.0-1'

Once we have a new queue entry we are able to accept it, step 2:

  >>> multibar_src_queue.setAccepted()
  >>> syncUpdate(multibar_src_queue)
  >>> multibar_src_queue.status.name
  'ACCEPTED'

We can just assume the source was published by step 3 and 4 for
simplicity and claim 'build from ACCEPTED' feature.

Build creation is done based on the SourcePackageRelease object, step 5:

  >>> from canonical.lp.dbschema import PackagePublishingPocket
  >>> multibar_build = multibar_spr.createBuild(
  ...     hoary['i386'], PackagePublishingPocket.RELEASE,
  ...     multibar_src_queue.archive)

  >>> multibar_build.buildstate.name
  'NEEDSBUILD'

We have just created a pending build record for hoary/i386.

Now we also assume that the build was dispatched by the slave-scanner
script, step 6.

On step 7, the slave-scanner collects the files generated on builders
and organises them as an ordinary binary upload having a changesfile
and the collection of DEB files produced.

At this point slave-scanner moves the upload to the appropriate path
(/srv/launchpad.net/builddmaster) and invokes process-upload.py with
the 'buildd' upload policy and the build record id.

  >>> buildd_policy = getPolicy(
  ...     name='buildd', distro='ubuntu', distroseries='hoary',
  ...     buildid=multibar_build.id)

  >>> multibar_bin_upload = NascentUpload(
  ...     datadir('suite/multibar_1.0-1/multibar_1.0-1_i386.changes'),
  ...     buildd_policy, mock_logger_quiet)
  >>> multibar_bin_upload.process()
  >>> success = multibar_bin_upload.do_accept()

Now that we have successfully processed the binaries coming from a
builder, step 8, we can check the status of the database entities
related to it.

We have a NEW queue entry, containing the Build results:

  >>> multibar_bin_queue = multibar_bin_upload.queue_root
  >>> multibar_bin_queue.status.name
  'NEW'
  >>> multibar_bin_queue.builds.count()
  1

The build considered as 'producer' of the upload binaries is the same
that we have created in step 5:

  >>> build = multibar_bin_queue.builds[0].build
  >>> build.id == multibar_build.id
  True

Also the build record was updated to FULLYBUILT in nascentupload domain.

  >>> build.buildstate.name
  'FULLYBUILT'

After certifying that the build record is marked as FULLYBUILT the
slave-scanner can safely update the build information (buildlog,
duration, etc) and clean the builder for anther job.

If the build record was not marked as FULLYBUILT during the
upload-time, it means that the slave should be hold with the builds
results for later processing.

Updating the build record as part of the upload processing avoids possible
inconsistencies when a binary upload was not processed correctly, then
was not stored in Launchpad database. The slave-scanner has no way to
recognise such situations easily, since process-upload exits with
success even when the upload is rejected. See bug #32261 for further info.

Chuck it all away again:

  >>> transaction.abort()


== Post-Release pockets uploads ==

And this time, try an upload to -updates, it'll have to be signed etc because
we're using the insecure policy to check everything in it end-to-end. We have
to set hoary to CURRENT in order to do this because we're not allowed
to upload to -UPDATES in a DEVELOPMENT series.

  >>> hoary.status = DistroSeriesStatus.CURRENT

Note that the policy do not have fixed distroseries, it will be
overridden by the changesfile:

  >>> norelease_sync_policy = getPolicy(
  ...     name='sync', distro='ubuntu')

  >>> ed_src = NascentUpload(
  ...     datadir('updates-upload-test/ed_0.2-20_source.changes'),
  ...     norelease_sync_policy, mock_logger_quiet)
  >>> ed_src.process()
  >>> ed_src.is_rejected
  False

  >>> success = ed_src.do_accept()

  >>> print ed_src.queue_root.pocket.name
  UPDATES

Even though this went to a pocket and thus would be unapproved rather
than accepted, the ed upload ought still make it to NEW instead of
unapproved.

  >>> print ed_src.queue_root.status.name
  NEW

And pop it back to development now that we're done

  >>> hoary.status = DistroSeriesStatus.DEVELOPMENT

Check the uploader behaviour against a missing orig.tar.gz file,
      bug # 30741.

  >>> ed21_src = NascentUpload(
  ...     datadir('ed-0.2-21/ed_0.2-21_source.changes'),
  ...     sync_policy, mock_logger_quiet)
  >>> ed21_src.process()
  >>> ed21_src.is_rejected
  True
  >>> print ed21_src.rejection_message+"\nEND"
  Unable to find ed_0.2.orig.tar.gz in upload or distribution.
  Files specified in DSC are broken or missing, skipping package unpack verification.
  END


== Installer source uploads doesn't contain 'Standards-Version' ==

Check if we can accept a installer-source upload which doesn't have
'Standards-Version' field in DSC. See bug #75874 for further
information.

  >>> inst_src = NascentUpload(
  ...     datadir('test75874_0.1_source.changes'),
  ...     sync_policy, mock_logger_quiet)
  >>> inst_src.process()

  >>> inst_src.is_rejected
  False

  >>> success = inst_src.do_accept()
  >>> success
  True

Look for the respective SourcePackageRelease entry and inspect its
content, it should have all the required fields except the
'dsc_standards_version':

  >>> inst_queue = hoary.getQueueItems(PackageUploadStatus.NEW,
  ...                                  name='test75874', exact_match=True)[0]
  >>> inst_spr = inst_queue.sources[0].sourcepackagerelease

  >>> inst_spr.dsc_maintainer_rfc822
  u'Colin Watson <cjwatson@ubuntu.com>'

  >>> inst_spr.dsc_binaries
  u'test75874'

  >>> inst_spr.dsc_standards_version is None
  True

Chuck it all away again

  >>> transaction.abort()


== Insecure Policy ==

'insecure' upload policy forces NascentUpload to perform ACLs over the
DSC signature. It only allows 'source' upload where both, changesfile
and DSC, should be signed.

Import the test keys again since the transaction was aborted before.

  >>> from canonical.launchpad.ftests import import_public_test_keys
  >>> import_public_test_keys()

When using 'insecure' policy, NascentUpload instace stores the DSC
sigining key reference as an IGPGKey:

  >>> bar_ok = NascentUpload(
  ...     datadir('suite/bar_1.0-1/bar_1.0-1_source.changes'),
  ...     insecure_policy, mock_logger_quiet)
  >>> bar_ok.process()
  >>> bar_ok.is_rejected
  False

  >>> from canonical.launchpad.webapp.testing import verifyObject
  >>> from canonical.launchpad.interfaces import (
  ...    IGPGKey, IPersonSet)

  >>> verifyObject(IGPGKey, bar_ok.changes.dsc.signingkey)
  True

  >>> verifyObject(IGPGKey, bar_ok.changes.signingkey)
  True

The second key of name16 person is used to sign uploads (the first gpgkey
record is a placeholder one, we used the second key):

  >>> name16 = getUtility(IPersonSet).getByName('name16')
  >>> uploader_key = name16.gpgkeys[1]

Both, DSC and changesfile were signed:

  >>> bar_ok.changes.dsc.signingkey.fingerprint == uploader_key.fingerprint
  True

  >>> bar_ok.changes.signingkey.fingerprint == uploader_key.fingerprint
  True

Let's modify the current ACL rules for ubuntu, moving the upload
rights to all components from 'ubuntu-team' to 'sabdfl':

  >>> new_uploader = getUtility(IPersonSet).getByName('sabdfl')
  >>> for distro_component in ubuntu.uploaders:
  ...     distro_component.uploader = new_uploader

This time the upload should fail because the ACLs don't let
"name16", the key owner, upload a package.

  >>> bar_failed = NascentUpload(
  ...     datadir('suite/bar_1.0-1/bar_1.0-1_source.changes'),
  ...     insecure_policy, mock_logger_quiet)

  >>> bar_failed.process()
  >>> bar_failed.is_rejected
  True
  >>> print bar_failed.rejection_message
  Signer has no upload rights at all to this distribution.

Even in a rejected upload using 'insecure' policy, the DSC signing key
and the changesfile sigining key are stored in NascentUpload instance
for further checks:

  >>> verifyObject(IGPGKey, bar_failed.changes.dsc.signingkey)
  True
  >>> verifyObject(IGPGKey, bar_failed.changes.signingkey)
  True

  >>> bar_failed.changes.dsc.signingkey.fingerprint == uploader_key.fingerprint
  True
  >>> bar_failed.changes.signingkey.fingerprint == uploader_key.fingerprint
  True

