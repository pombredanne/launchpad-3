= NascentUploadFiles =

Files related with an Soyuz upload are modelled as:

 * ChangesFile: the upload changesfile;
   * DSCFile: the upload DSC file for source uploads;
     * DSCUploadedFile: used to check consistency of the files
                        mentioned in DSC;
   * SourceUploadFile: source files like ORIG and DIFF;
   * UDebBinaryUploadFile: udeb package file;
   * DebBinaryUploadFile: deb package file;
   * CustomUploadFile: normally a tarball used for custom uploads.

Import the test keys so we have them ready for verification

  >>> from canonical.launchpad.ftests import import_public_test_keys
  >>> import_public_test_keys()

We need to be logged into the security model in order to get any further

  >>> login('foo.bar@canonical.com')
  >>> from canonical.archiveuploader.tests import (
  ...    datadir, getPolicy, mock_logger, mock_logger_quiet)


== ChangesFile  ==

A changesfile contains manifest of what is included (ou should be
considered) for the upload in question.

  >>> modified_insecure_policy = getPolicy(
  ...     name='insecure', distro='ubuntu', distroseries='hoary')
  >>> modified_insecure_policy.can_upload_binaries = True
  >>> modified_insecure_policy.can_upload_mixed = True

  >>> from canonical.archiveuploader.changesfile import ChangesFile

  >>> ed_mixed_changes = ChangesFile(
  ...     datadir('ed_0.2-20_i386.changes'),
  ...     modified_insecure_policy, mock_logger_quiet)

At this point the changesfile content is already parsed:

  >>> ed_mixed_changes.source
  'ed'
  >>> ed_mixed_changes.version
  '0.2-20'
  >>> ed_mixed_changes.architectures
  set(['source', 'i386'])
  >>> ed_mixed_changes.suite_name
  'unstable'

Push upload targeted suite into policy before the checks, nomally done
by NascentUpload object:

  >>> modified_insecure_policy.setDistroSeriesAndPocket(
  ...      ed_mixed_changes.suite_name)


Build contained objects, any error during this process will be stored
in the returned generator. This way all the checks are performed and
we can deal with the errors later:

  >>> errors = ed_mixed_changes.processFiles()
  >>> errors
  <generator ...>
  >>> len(list(errors))
  0

At this point we can inspect the list of files contained in the upload.

  >>> for uploaded_file in ed_mixed_changes.files:
  ...     print uploaded_file.filename
  ed_0.2-20.dsc
  ed_0.2-20.diff.gz
  ed_0.2-20_i386.deb

  >>> [f.filename for f in ed_mixed_changes.binary_package_files]
  ['ed_0.2-20_i386.deb']

  >>> [f.filename for f in ed_mixed_changes.source_package_files]
  ['ed_0.2-20.dsc', 'ed_0.2-20.diff.gz']


Similar to what we have in 'processFiles' ChangesFile.verify is also
a error generator

  >>> errors = ed_mixed_changes.verify()
  >>> len(list(errors))
  0


=== CustomUploadFile identification ===

Source and Binary files are easily recognized by a regexp on the
filenames:

 >>> from canonical.archiveuploader.utils import (
 ...     re_isadeb, re_issource)

 >>> bin_match = re_isadeb.match('foo-bar_1.0_i386.deb')
 >>> bin_match.group(0)
 'foo-bar_1.0_i386.deb'
 >>> bin_match.group(1)
 'foo-bar'
 >>> bin_match.group(2)
 '1.0'
 >>> bin_match.group(3)
 'i386'

 >>> src_match = re_issource.match('foo_1.0.orig.tar.gz')
 >>> src_match.group(0)
 'foo_1.0.orig.tar.gz'
 >>> src_match.group(1)
 'foo'
 >>> src_match.group(2)
 '1.0'
 >>> src_match.group(3)
 'orig.tar.gz'

 >>> src_match = re_issource.match('foo_1.0.tar.gz')
 >>> src_match.group(0)
 'foo_1.0.tar.gz'
 >>> src_match.group(1)
 'foo'
 >>> src_match.group(2)
 '1.0'
 >>> src_match.group(3)
 'tar.gz'

 >>> src_match = re_issource.match('foo_1.0.diff.gz')
 >>> src_match.group(0)
 'foo_1.0.diff.gz'
 >>> src_match.group(1)
 'foo'
 >>> src_match.group(2)
 '1.0'
 >>> src_match.group(3)
 'diff.gz'

 >>> src_match = re_issource.match('foo_1.0.dsc')
 >>> src_match.group(0)
 'foo_1.0.dsc'
 >>> src_match.group(1)
 'foo'
 >>> src_match.group(2)
 '1.0'
 >>> src_match.group(3)
 'dsc'

And finally a failure:

 >>> re_issource.match('foo_1.0.c') is None
 True


However a custom upload is essencially a tarball, so it matches the
is_source regexp:

 >>> src_match = re_issource.match('dist-upgrader_1.0.tar.gz')
 >>> src_match.group(0)
 'dist-upgrader_1.0.tar.gz'
 >>> src_match.group(1)
 'dist-upgrader'
 >>> src_match.group(2)
 '1.0'
 >>> src_match.group(3)
 'tar.gz'


That's why we recognize them by identifying a set of custom sections:

 * raw-installer
 * raw-translations
 * raw-dist-upgrader
 * raw-ddtp-tarball

The Changesfile.isCustom receives a 'component_and_section' chunk from
the respective file line in the changesfile and return True if it is
target to a custom section.

We will use the current upload available and test the known
'component_and_section' schemas.

Note that the component_name and section_name are not checked for
sanity, it'll be done later on, this method only checks if the
section_name startswith 'raw-':

 >>> ed_mixed_changes.isCustom('foo-bar')
 False
 >>> ed_mixed_changes.isCustom('drops/foo-bar')
 False
 >>> ed_mixed_changes.isCustom('drops/raw-biscuit')
 True
 >>> ed_mixed_changes.isCustom('drops/rawbiscuit')
 False
 >>> ed_mixed_changes.isCustom('drops/raw-biscuit/something')
 True
 >>> ed_mixed_changes.isCustom('main/raw-installer')
 True
 >>> ed_mixed_changes.isCustom('main/law-installer')
 False

See the CustomUploadFile checks below for specific checks on custom
uploads.


=== ChangesFile Parsing Addresses ===

Address parsing is implemented by the SignableTagFile class, which
is base for ChangesFile and DSCFile.

  >>> from canonical.archiveuploader.dscfile import SignableTagFile
  >>> sig_file = SignableTagFile()

Note that the policy.{distroseries, pocket} must be already
initialised before issuing any parse request, otherwise we can't
generate proper PERSON_CREATION_RATIONALE_MESSAGES.

  >>> sig_file_policy = getPolicy(name='insecure', distro='ubuntu')
  >>> sig_file_policy.setDistroSeriesAndPocket('hoary')
  >>> sig_file.policy = sig_file_policy

Some fields extracted from the tag_file are required, they are always
present in ChangesFile and DSCFile:

  >>> sig_file._dict = {}
  >>> sig_file._dict['source'] = 'some-source'
  >>> sig_file._dict['version'] = '6.6.6'


After initiliasing sig_file we can parse addresses and look them up in
Launchpad:

  >>> addr = sig_file.parseAddress("Foo Bar <foo.bar@canonical.com>")
  >>> addr['person'].displayname
  u'Foo Bar'
  >>> addr['person'].creation_comment is None
  True


If the address is unparsable, we get an error.

  >>> sig_file.parseAddress("Cannot Parse Me <FOOO>")
  Traceback (most recent call last):
  ...
  UploadError: Cannot Parse Me <FOOO>: no @ found in email address part.


If the email address is not yet registered and policy.create_people is True,
a new Person will be created.

  >>> sig_file.policy.create_people
  True

  >>> addr = sig_file.parseAddress("Baz <baz@canonical.com>")
  >>> addr['person'].creation_rationale.name
  'SOURCEPACKAGEUPLOAD'

  >>> addr['person'].creation_comment
  u'when the some-source_6.6.6 package was uploaded to hoary/RELEASE'


If the use an un-initialised policy to create a launchpad person the
creation_rationale will still be possible, however missing important
information, the upload target:

  >>> sig_file.policy.distroseries = None

  >>> addr = sig_file.parseAddress("Bar <bar@canonical.com>")
  >>> addr['person'].creation_rationale.name
  'SOURCEPACKAGEUPLOAD'

  >>> addr['person'].creation_comment
  u'when the some-source_6.6.6 package was uploaded to (unknown)'


On ChangesFile objects we can have access to the enhanced address_structure
corresponding to the RFC-822 mentioned after performing 'processAddress':

  >>> ed_mixed_changes.maintainer is None
  True

  >>> errors = ed_mixed_changes.processAddresses()
  >>> len(list(errors))
  0

As we can see, this method also return an error generator.

The built address_structure contains values that will be used during
the upload processing:

  >>> ed_mixed_changes.maintainer['rfc822']
  'James Troup <james@nocrew.org>'
  >>> ed_mixed_changes.maintainer['rfc2047']
  'James Troup <james@nocrew.org>'
  >>> ed_mixed_changes.maintainer['name']
  'James Troup'
  >>> ed_mixed_changes.maintainer['email']
  'james@nocrew.org'
  >>> ed_mixed_changes.maintainer['person']
  <Person ...>


=== Signature Traces ===

Changes file can be optionally GPG-signed, so ChangesFile has
infrastructure to record this information for later checks with policy
requirements.

The ChangesFile signer IPerson, used to checks upload ACL, normally
know as 'sponsor' or 'mentor':

  >>> ed_mixed_changes.signer.displayname
  u'Foo Bar'

The IGPGKey used to sign this ChangesFile:

  >>> ed_mixed_changes.signingkey.displayname
  u'1024D/6C64A8C5'

The IGPGKey fingerprint used to sign this ChangesFile:

  >>> ed_mixed_changes.fingerprint
  '340CA3BB270E2716C9EE0B768E7EB7086C64A8C5'


== DSCFile ==

DSCFile class models the operations and checks needed for processing
and storing a DSC file in the LP system.

The DSC file itself contains information about what was used to build
the given version of source.

  >>> from canonical.archiveuploader.dscfile import (
  ...    DSCFile, DSCUploadedFile)

  >>> ed_mixed_dsc = DSCFile(
  ...     datadir('ed_0.2-20.dsc'),
  ...     'e31eeb0b6b3b87e1ea79378df864be18', 522, 'editors',
  ...     'important', 'ed', '0.2-20', ed_mixed_changes,
  ...     modified_insecure_policy, mock_logger_quiet)

  >>> ed_mixed_dsc
  <canonical.archiveuploader.dscfile.DSCFile ...>

So this object is exactly the same than what we already have created
in the ChangesFile instance.

  >>> ed_mixed_changes.dsc
  <canonical.archiveuploader.dscfile.DSCFile ...>

The DSCFile also presents a similar behaviour to access its parsed
contents:

  >>> ed_mixed_dsc.source
  'ed'
  >>> ed_mixed_dsc.version
  '0.2-20'
  >>> ed_mixed_dsc.architecture
  'any'
  >>> ed_mixed_dsc.binary
  'ed'

The DSC is GPG-signed most of the time, so we can guarantee who was
the author. The DSCFile class implements the same address parsing
methods found in ChangesFile:

  >>> ed_mixed_dsc.maintainer['rfc822']
  'James Troup <james@nocrew.org>'

The DSC signer IPerson:

  >>> ed_mixed_dsc.signer.displayname
  u'Foo Bar'

The IGPGKey used to sign this DSC, which will be stored as the
ISourcePackageRelease.dscsiginingkey:

  >>> ed_mixed_dsc.signingkey.displayname
  u'1024D/6C64A8C5'

The IGPGKey fingerprint used to sign this DSC:

  >>> ed_mixed_dsc.fingerprint
  '340CA3BB270E2716C9EE0B768E7EB7086C64A8C5'

A DSCFile provides a verification API similiar to what we have in
ChangesFile itself:

  >>> errors = ed_mixed_dsc.verify()
  >>> errors
  <generator ...>
  >>> len(list(errors))
  0

Apart of other consisteny checks DSCFile is able to check also ensure
the digest declared in in the DSC matches the content of the files on
disk:

  >>> ed_broken_dsc = DSCFile(
  ...     datadir('ed_0.2-20.dsc'),
  ...     'e31eeb0b6b3b87e1ea79378df864ffff', 500, 'editors',
  ...     'important', 'ed', '0.2-20', ed_mixed_changes,
  ...     modified_insecure_policy, mock_logger_quiet)

  >>> errors = ed_broken_dsc.verify()
  >>> [str(err) for err in errors]
  ['File ed_0.2-20.dsc mentioned in the changes has a checksum mismatch. e31eeb0b6b3b87e1ea79378df864be18 != e31eeb0b6b3b87e1ea79378df864ffff']


=== Sub-DSC files or DSCUploadedFiles ===

Sub-DSCFiles are DSCUploadedFile objects.

  >>> ed_mixed_dsc.files[0]
  <canonical.archiveuploader.dscfile.DSCUploadedFile ...>

We can also inspect the list of files declared in this DSC:

  >>> for dsc_file in ed_mixed_dsc.files:
  ...     print dsc_file.filename
  ed_0.2.orig.tar.gz
  ed_0.2-20.diff.gz

The DSCUploadedFile also inherit the ability to verify file sanity:

  >>> ed_broken_dsc_file = DSCUploadedFile(
  ...     datadir('ed_0.2-20.diff.gz'),
  ...     'f9e1e5f13725f581919e9bfd6227ffff', 500,
  ...     modified_insecure_policy, mock_logger_quiet)
  >>> errors = ed_broken_dsc_file.verify()
  >>> [str(err) for err in errors]
  ['File ed_0.2-20.diff.gz mentioned in the changes has a checksum mismatch. f9e1e5f13725f581919e9bfd62272a05 != f9e1e5f13725f581919e9bfd6227ffff']


=== Sub-DSC file lookup ===


== SourceUploadFile ==


== DebBinaryUploadFile ==


== UDebBinaryUploadFile ==


== CustomUploadFile ==


